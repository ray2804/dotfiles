<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" dir="ltr"><head><table cellpadding=0 cellspacing=0><tr><td><img src="icon:///24/lightbulb.png" /></td><td width="5"></td><td><h2 class="firstHeading" id="firstHeading">Support Vector Machine</h4></td></tr></table><hr noshade="true"></head>
<body class="mediawiki ltr ns-0 ns-subject page-Support_Vector_Machine skin-monobook">
<div id="content">
	
	
	
	<div id="bodyContent">
		
		
		
		
<div id="synopsis">
<h4>
<span class="mw-headline" id="Synopsis">Synopsis</span>
</h4>
<p>
JMySVMLearner provides an internal Java implementation of the mySVM by Stefan Rueping.
</p>
</div><br/><h4> <span class="mw-headline" id="Description"> Description </span>
</h4>
<p>This learner uses the Java implementation of the support vector machine <i>mySVM</i> by Stefan RÃ¼ping. This learning method can be used for both regression and classification and provides a fast algorithm and good results for many learning tasks.


</p><br/><h4> <span class="mw-headline" id="Input"> Input </span>
</h4>

<ul class="ports">
<li> <b>training set</b>: <i>expects:</i> ExampleSet
</li>
</ul><br/><h4> <span class="mw-headline" id="Output"> Output </span>
</h4>

<ul class="ports">
<li> <b>model</b>:
</li>
<li> <b>estimated performance</b>:
</li>
<li> <b>weights</b>:
</li>
<li> <b>exampleSet</b>:
</li>
</ul><br/><h4> <span class="mw-headline" id="Parameters"> Parameters </span>
</h4>

<ul class="ports">
<li> <b>kernel type</b>:  The SVM kernel type
</li>
<li> <b>kernel gamma</b>:  The SVM kernel parameter gamma.
</li>
<li> <b>kernel sigma1</b>:  The SVM kernel parameter sigma1.
</li>
<li> <b>kernel sigma2</b>:  The SVM kernel parameter sigma2.
</li>
<li> <b>kernel sigma3</b>:  The SVM kernel parameter sigma3.
</li>
<li> <b>kernel shift</b>:  The SVM kernel parameter shift.
</li>
<li> <b>kernel degree</b>:  The SVM kernel parameter degree.
</li>
<li> <b>kernel a</b>:  The SVM kernel parameter a.
</li>
<li> <b>kernel b</b>:  The SVM kernel parameter b.
</li>
<li> <b>kernel cache</b>:  Size of the cache for kernel evaluations im MB
</li>
<li> <b>C</b>:  The SVM complexity constant. Use -1 for different C values for positive and negative.
</li>
<li> <b>convergence epsilon</b>:  Precision on the KKT conditions
</li>
<li> <b>max iterations</b>:  Stop after this many iterations
</li>
<li> <b>scale</b>:  Scale the example values and store the scaling parameters for test set.
</li>
<li> <b>calculate weights</b>:  Indicates if attribute weights should be returned.
</li>
<li> <b>return optimization performance</b>:  Indicates if final optimization fitness should be returned as performance.
</li>
<li> <b>L pos</b>:  A factor for the SVM complexity constant for positive examples
</li>
<li> <b>L neg</b>:  A factor for the SVM complexity constant for negative examples
</li>
<li> <b>epsilon</b>:  Insensitivity constant. No loss if prediction lies this close to true value
</li>
<li> <b>epsilon plus</b>:  Epsilon for positive deviation only
</li>
<li> <b>epsilon minus</b>:  Epsilon for negative deviation only
</li>
<li> <b>balance cost</b>:  Adapts Cpos and Cneg to the relative size of the classes
</li>
<li> <b>quadratic loss pos</b>:  Use quadratic loss for positive deviation
</li>
<li> <b>quadratic loss neg</b>:  Use quadratic loss for negative deviation
</li>
<li> <b>estimate performance</b>:  Indicates if this learner should also return a performance estimation.
</li>
</ul><br/><h4> <span class="mw-headline" id="ExampleProcess"> ExampleProcess </span>
</h4><br/><div>
</div>
</body>
</html>
