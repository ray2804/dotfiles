<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" dir="ltr"><head><table cellpadding=0 cellspacing=0><tr><td><img src="icon:///24/symbol_percent.png" /></td><td width="5"></td><td><h2 class="firstHeading" id="firstHeading">X-Validation</h4></td></tr></table><hr noshade="true"></head>
<body class="mediawiki ltr ns-0 ns-subject page-X-Validation skin-monobook">
<div id="content">
	
	
	
	<div id="bodyContent">
		
		
		
		
<div id="synopsis">
<h4>
<span class="mw-headline" id="Synopsis">Synopsis</span>
</h4>
<p>
X-Validation encapsulates a cross-validation in order to estimate the performance of a learning operator.
</p>
</div><br/><h4> <span class="mw-headline" id="Description"> Description </span>
</h4>
<p>
<code>X-Validation</code> performs a cross-validation process. The input <i>ExampleSet</i>       <i>S</i> is split up into <var>number of validations</var> subsets <i>S_i</i>.       The inner subprocesses are applied <var>number of validations</var>       times using <i>S_i</i> as the test set (input of the <i>Testing</i>       subprocess) and <i>S \ S_i</i> as training set (input of the <i>Training</i>       subprocess).    
</p>
<p>
The <i>Training</i> subprocess must return a model, which is usually       trained on the input <i>ExampleSet.</i> The <i>Testing</i> subprocess       must return a <i>PerformanceVector</i>. This is usually generated by       applying the model and measuring it's performance. Additional objects       might be passed from the <i>Training</i> to the <i>Testing</i>       subprocess using the through ports. Please note that the performance calculated by this estimation scheme is only an estimation of the performance which would be achieved with the model built on the complete delivered data set instead of an exact calculation. Exactly this model, hence the one built on the complete input data, is delivered at the corresponding port in order to give convenient access to this model. 
</p>

<p>
Like other validation schemes the RapidMiner cross validation can use       several types of sampling for building the subsets    
</p>
<p>
Linear sampling simply divides the example set into partitions without       changing the order of the examples. Shuffled sampling build random       subsets from the data. Stratifed sampling builds random subsets and       ensures that the class distribution in the subsets is the same as in the       whole example set. For having the random splits independent from the rest of the process, a local random seed might be used. See the parameters       for details.    
</p>

<p>
The cross validation operator provides several values which can be       logged by means of a     
</p>
<p>
<a href="/wiki/index.php?title=Log" shape="rect" title="Log">Log</a>
&lt;/p&gt;
</p>
<p>
    

&lt;p&gt;
. Of course the number of the current iteration can be logged which       might be useful for ProcessLog operators wrapped inside a cross       validation. Beside that, all performance estimation operators of       RapidMiner provide access to the average values calculated during the       estimation. Since the operator cannot ensure the names of the delivered       criteria, the ProcessLog operator can access the values via the generic       value names:    
</p>

<ul class="ports">
<li>         performance: the value for the main criterion calculated by this         validation operator      
</li>
<li>         performance1: the value of the first criterion of the performance         vector calculated      
</li>
<li>         performance2: the value of the second criterion of the performance         vector calculated      
</li>
<li>         performance3: the value of the third criterion of the performance         vector calculated      
</li>
<li>         for the main criterion, also the variance and the standard deviation         can be accessed where applicable.
</li>
</ul><br/><h4> <span class="mw-headline" id="Input"> Input </span>
</h4>

<ul class="ports">
<li> <b>training</b>: <i>expects:</i> ExampleSet
</li>
</ul><br/><h4> <span class="mw-headline" id="Output"> Output </span>
</h4>

<ul class="ports">
<li> <b>model</b>:
</li>
<li> <b>training</b>:
</li>
<li> <b>averagable 1</b>:
</li>
<li> <b>averagable 2</b>:
</li>
</ul><br/><h4> <span class="mw-headline" id="Parameters"> Parameters </span>
</h4>

<ul class="ports">
<li> <b>create complete model</b>:  Indicates if a model of the complete data set should be additionally build after estimation.
</li>
<li> <b>average performances only</b>:  Indicates if only performance vectors should be averaged or all types of averagable result vectors
</li>
<li> <b>leave one out</b>:  Set the number of validations to the number of examples. If set to true, number_of_validations is ignored
</li>
<li> <b>number of validations</b>:  Number of subsets for the crossvalidation.
</li>
<li> <b>sampling type</b>:  Defines the sampling type of the cross validation (linear = consecutive subsets, shuffled = random subsets, stratified = random subsets with class distribution kept constant)
</li>
<li> <b>use local random seed</b>:  Indicates if a local random seed should be used.
</li>
<li> <b>local random seed</b>:  Specifies the local random seed
</li>
</ul><br/><h4> <span class="mw-headline" id="ExampleProcess"> ExampleProcess </span>
</h4><br/><div>
</div>
</body>
</html>
